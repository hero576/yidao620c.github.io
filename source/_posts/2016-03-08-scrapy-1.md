---
title: "基于Scrapy的分布式爬虫框架（1）"
date: 2016-03-08 10:59:15 +0800
comments: true
categories: python
tags: [scrapy]
---

## 简介

Scrapy是一个为了爬取网站数据，提取结构性数据而编写的应用框架。
可以应用在包括数据挖掘，信息处理或存储历史数据等一系列的程序中。
其最初是为了页面抓取(更确切来说,网络抓取)所设计的，
也可以应用在获取API所返回的数据(比如Web Services)或者通用的网络爬虫。

涉及到更进阶的东西比如爬取时的网站认证、内容的分析处理、重复抓取、分布式爬取等等也时间很复杂的事。
而Scrapy都能帮你实现高阶的爬虫框架。<!--more-->

对一个通用的爬虫个，我们要定义：

抓取策略，那些网页是我们需要去下载的，那些是无需下载的，那些网页是我们优先下载的，定义清楚之后，能节省很多无谓的爬取
更新策略，监控列表页来发现新的页面；定期check页面是否过期等等
抽取策略，我们应该如何的从网页中抽取我们想要的内容，不仅仅包含最终的目标内容，还有下一步要抓取的url
抓取频率，我们需要合理的去下载一个网站，却又不失效率

